{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNQuestionSimilarity",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/shivasv97/NSSH/blob/master/RNNQuestionSimilarity.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "n5JvVGzkOZ1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Required files for running the below code.\n",
        "\n",
        "api_client.py\n",
        "\n",
        "quora_questions.pkl (if not using the API client to fetch data)\n",
        "\n",
        "glove.6B.zip (obtained after downloading the glove file below)"
      ]
    },
    {
      "metadata": {
        "id": "f5CrfjfjM315",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Installing pydot and graphviz for Model plot.\n",
        "Run the below commands and then restart runtime for effects to take place."
      ]
    },
    {
      "metadata": {
        "id": "10KQrQ2uui3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ea63962-a885-4944-a00e-54dcff35443a"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q pydot\n",
        "!pip install graphviz"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "op3fST3BM0dB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Downloading Glove embeddings"
      ]
    },
    {
      "metadata": {
        "id": "Swc3iA0xLDZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1df9a35f-6270-434b-c3d7-34fb03b9e8a6"
      },
      "cell_type": "code",
      "source": [
        " !wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log.1’.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jYoJbZk2MbMv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# nltk downloads for text preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "HNzkumijUwFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "1199c4ee-5535-42cf-92eb-a431a137a101"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "Vlaz90FCMjTM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# neccessary imports"
      ]
    },
    {
      "metadata": {
        "id": "EiP1RSOKZw0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import pydot, graphviz\n",
        "from keras.utils import plot_model\n",
        "\n",
        "import pickle\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import datetime\n",
        "from time import time\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import sys\n",
        "import io\n",
        "\n",
        "from itertools import islice\n",
        "import itertools\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEsMIy-6Mn5N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Global Variables"
      ]
    },
    {
      "metadata": {
        "id": "L5DhztLHZKUU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8zHgwebNMuMT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ZIP extract for Glove embeddings downloaded"
      ]
    },
    {
      "metadata": {
        "id": "_pXL-AXYcszk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile(\"glove.6B.zip.1\", 'r')\n",
        "zip_ref.extractall(\".\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4v1k53cUNHJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code to stream data from the API client.\n",
        "Has been converted to text since API has been shutdown by admin."
      ]
    },
    {
      "metadata": {
        "id": "W_rdYEEJNzOJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "import api_client\n",
        "def getData(size):\n",
        "  client = api_client.ApiClient(\"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1NTQ2MjY2NDgsImlhdCI6MTUzOTA3NDY0OCwibmJmIjoxNTM5MDc0NjQ4LCJpZGVudGl0eSI6OH0.zJcMa4ZquR6AeXyoLlqaB8H-8VCWGwulaWdv7qHIn_o\")\n",
        "  data = client.get_kaggle_quora_data(size)\n",
        "  return data\n",
        "  \n",
        "  \n",
        "dat = getData(10000)\n",
        "dat1 = getData(10000)\n",
        "dat2 = getData(10000)\n",
        "dat3 = getData(10000)\n",
        "dat = dat + dat1 + dat2 + dat3\n",
        "print(len(dat))\n",
        "print(type(dat))"
      ]
    },
    {
      "metadata": {
        "id": "dclGiKlkNQ0_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Saved dataset to be loaded from pickle file."
      ]
    },
    {
      "metadata": {
        "id": "jBeav4MKw17J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "with open(r\"quora_questions.pkl\", \"rb\") as input_file:\n",
        "  pickl_data = pickle.load(input_file)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5X5OUT8NYs2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Functions for Preprocessing and Embedding indices creation."
      ]
    },
    {
      "metadata": {
        "id": "uuFtgz-NMdi3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_maxlen(sequences):\n",
        "  \n",
        "  return len(max(sequences,key = lambda x: len(x)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D9tD7DaxHOZo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "with io.open('glove.6B.50d.txt', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:],dtype='float32')\n",
        "        embeddings_index[word] = coefs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2C3W8MhOW_9I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_embed_matrix(word_index, embeddings_index):\n",
        "  embedding_matrix = np.zeros((len(word_index)+1, EMBEDDING_DIM))\n",
        "  for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all-zeros.\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "      \n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LoVh0ESemgAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess(dat,voc_size):\n",
        "  from nltk.tokenize import word_tokenize as wt\n",
        "  from collections import Counter\n",
        "  # code to create the vocabulary\n",
        "  stop_word = stopwords.words('english')\n",
        "  tok = Tokenizer(lower=True)\n",
        "  wor_list = []\n",
        "  que_list = []\n",
        "  question1 = []\n",
        "  question2 = []\n",
        "  labels = []\n",
        "  for i in dat:\n",
        "    #toks1 = list(wt(i['question1']))\n",
        "    #tokens1 = [w.lower() for w in tok1]\n",
        "\n",
        "    #wor_list += list(wt(i['question2']))\n",
        "    q1 = i['question1']\n",
        "    q2 = i['question2']\n",
        "    q1 = ' '.join([word for word in q1.split() if word not in stop_word])\n",
        "    q2 = ' '.join([word for word in q2.split() if word not in stop_word])\n",
        "    question1.append(q1)\n",
        "    question2.append(q2)\n",
        "\n",
        "    labels.append(int(i['is_duplicate']))\n",
        "\n",
        "  que_list = question1+question2\n",
        "  \n",
        "  tok.fit_on_texts(que_list)\n",
        "  temp_voc = tok.word_index\n",
        "\n",
        "  i= 0\n",
        "  size = voc_size\n",
        "  voc_words = list(temp_voc.keys())\n",
        "  final_vocab = {}\n",
        "  while(i < size):\n",
        "    final_vocab[voc_words[i]] = temp_voc[voc_words[i]]\n",
        "    i+=1\n",
        "    \n",
        "  padding = get_maxlen(que_list)\n",
        "  q1_seq = np.array(pad_sequences(tok.texts_to_sequences(question1),maxlen = padding))\n",
        "  q2_seq = np.array(pad_sequences(tok.texts_to_sequences(question2),maxlen = padding))\n",
        "  \n",
        "  q1_train,q1_test,q2_train,q2_test,label_train,label_test=train_test_split(q1_seq,q2_seq,labels,test_size=0.15, random_state=42)\n",
        "  \n",
        "  return  padding,q1_train,q1_test,q2_train,q2_test,label_train,label_test,final_vocab\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tJl8SgqrNh4V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creation of Train and Test datasets along with Embedding matrix"
      ]
    },
    {
      "metadata": {
        "id": "c4vX7DyGkDrj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LENGTH,q1_train,q1_test,q2_train,q2_test,label_train,label_test,word_to_index_map = preprocess(pickl_data,10000)\n",
        "\n",
        "#print(word_to_index_map)\n",
        "embedding_matrix = create_embed_matrix(word_to_index_map, embeddings_index)\n",
        "#print(embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKVRRupwvGq5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# debug code\n",
        "# print(embeddings_index[\"what\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rlbgYFAkKIwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# redundant code\n",
        "def word_to_index(vocab):\n",
        "  word_to_index_map = {w : i for i, w in enumerate(vocab)}\n",
        "  return word_to_index_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-a2bKYJxW86j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **LSTM Model with Manhattan Distance  **"
      ]
    },
    {
      "metadata": {
        "id": "U3EKFL6AW8EI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "7c061ab5-4787-475d-ded5-93d16060db42"
      },
      "cell_type": "code",
      "source": [
        "# Model variables\n",
        "n_hidden = 50\n",
        "gradient_clipping_norm = 1.25\n",
        "batch_size = 1024\n",
        "n_epoch = 20\n",
        "def exponent_neg_manhattan_distance(left, right):\n",
        "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
        "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
        "\n",
        "# The visible layer\n",
        "left_input = Input(shape=(MAX_SEQ_LENGTH,), dtype='int32')\n",
        "right_input = Input(shape=(MAX_SEQ_LENGTH,), dtype='int32')\n",
        "\n",
        "embedding_layer = Embedding(len(embedding_matrix), EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQ_LENGTH, trainable=False)\n",
        "\n",
        "# Embedded version of the inputs\n",
        "encoded_left = embedding_layer(left_input)\n",
        "encoded_right = embedding_layer(right_input)\n",
        "\n",
        "# Since this is a siamese network, both sides share the same LSTM\n",
        "shared_lstm = LSTM(n_hidden)\n",
        "\n",
        "left_output = shared_lstm(encoded_left)\n",
        "right_output = shared_lstm(encoded_right)\n",
        "\n",
        "# Calculates the distance as defined by the MaLSTM model\n",
        "malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
        "\n",
        "# Pack it all up into a model\n",
        "malstm = Model([left_input, right_input], [malstm_distance])\n",
        "\n",
        "# Adadelta optimizer, with gradient clipping by norm\n",
        "optimizer = Adadelta(clipnorm=gradient_clipping_norm)\n",
        "\n",
        "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "malstm.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 709)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 709)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 709, 50)      500050      input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 50)           20200       embedding_2[0][0]                \n",
            "                                                                 embedding_2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 1)            0           lstm_2[0][0]                     \n",
            "                                                                 lstm_2[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 520,250\n",
            "Trainable params: 20,200\n",
            "Non-trainable params: 500,050\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jL9AD-z7N1vN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Start Training with Validation."
      ]
    },
    {
      "metadata": {
        "id": "bW4jpo5X2Wki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "outputId": "387b9b34-7664-498d-d994-9473ff80aaa5"
      },
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "training_start_time = time()\n",
        "\n",
        "malstm_trained = malstm.fit([q1_train, q2_train], label_train, batch_size=batch_size, nb_epoch=n_epoch,\n",
        "                            validation_data=([q1_test,q2_test], label_test))\n",
        "\n",
        "print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 34000 samples, validate on 6000 samples\n",
            "Epoch 1/20\n",
            "34000/34000 [==============================] - 106s 3ms/step - loss: 0.2855 - acc: 0.6478 - val_loss: 0.2642 - val_acc: 0.6645\n",
            "Epoch 2/20\n",
            "34000/34000 [==============================] - 105s 3ms/step - loss: 0.2528 - acc: 0.6601 - val_loss: 0.2359 - val_acc: 0.6757\n",
            "Epoch 3/20\n",
            "34000/34000 [==============================] - 104s 3ms/step - loss: 0.2283 - acc: 0.6759 - val_loss: 0.2193 - val_acc: 0.6820\n",
            "Epoch 4/20\n",
            "34000/34000 [==============================] - 103s 3ms/step - loss: 0.2156 - acc: 0.6855 - val_loss: 0.2119 - val_acc: 0.6903\n",
            "Epoch 5/20\n",
            "34000/34000 [==============================] - 103s 3ms/step - loss: 0.2092 - acc: 0.6917 - val_loss: 0.2082 - val_acc: 0.6930\n",
            "Epoch 6/20\n",
            "34000/34000 [==============================] - 103s 3ms/step - loss: 0.2049 - acc: 0.6956 - val_loss: 0.2052 - val_acc: 0.6960\n",
            "Epoch 7/20\n",
            "34000/34000 [==============================] - 105s 3ms/step - loss: 0.2013 - acc: 0.6986 - val_loss: 0.2026 - val_acc: 0.6973\n",
            "Epoch 8/20\n",
            "34000/34000 [==============================] - 104s 3ms/step - loss: 0.1982 - acc: 0.7022 - val_loss: 0.2003 - val_acc: 0.6972\n",
            "Epoch 9/20\n",
            "34000/34000 [==============================] - 106s 3ms/step - loss: 0.1954 - acc: 0.7049 - val_loss: 0.1986 - val_acc: 0.6973\n",
            "Epoch 10/20\n",
            "34000/34000 [==============================] - 105s 3ms/step - loss: 0.1934 - acc: 0.7066 - val_loss: 0.1966 - val_acc: 0.7020\n",
            "Epoch 11/20\n",
            "34000/34000 [==============================] - 104s 3ms/step - loss: 0.1916 - acc: 0.7090 - val_loss: 0.1957 - val_acc: 0.7007\n",
            "Epoch 12/20\n",
            "34000/34000 [==============================] - 105s 3ms/step - loss: 0.1902 - acc: 0.7118 - val_loss: 0.1952 - val_acc: 0.7008\n",
            "Epoch 13/20\n",
            "34000/34000 [==============================] - 105s 3ms/step - loss: 0.1889 - acc: 0.7135 - val_loss: 0.1938 - val_acc: 0.7030\n",
            "Epoch 14/20\n",
            "34000/34000 [==============================] - 103s 3ms/step - loss: 0.1881 - acc: 0.7159 - val_loss: 0.1943 - val_acc: 0.7037\n",
            "Epoch 15/20\n",
            "34000/34000 [==============================] - 104s 3ms/step - loss: 0.1871 - acc: 0.7179 - val_loss: 0.1926 - val_acc: 0.7070\n",
            "Epoch 16/20\n",
            "34000/34000 [==============================] - 105s 3ms/step - loss: 0.1863 - acc: 0.7199 - val_loss: 0.1927 - val_acc: 0.7068\n",
            "Epoch 17/20\n",
            "34000/34000 [==============================] - 105s 3ms/step - loss: 0.1857 - acc: 0.7223 - val_loss: 0.1922 - val_acc: 0.7088\n",
            "Epoch 18/20\n",
            "34000/34000 [==============================] - 103s 3ms/step - loss: 0.1851 - acc: 0.7236 - val_loss: 0.1914 - val_acc: 0.7088\n",
            "Epoch 19/20\n",
            "34000/34000 [==============================] - 103s 3ms/step - loss: 0.1845 - acc: 0.7235 - val_loss: 0.1915 - val_acc: 0.7105\n",
            "Epoch 20/20\n",
            "34000/34000 [==============================] - 104s 3ms/step - loss: 0.1840 - acc: 0.7253 - val_loss: 0.1908 - val_acc: 0.7105\n",
            "Training time finished.\n",
            "20 epochs in 0:34:47.103109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Hwb76ikOIFo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving the input data as a pickle file, do not run if api client is not available\n",
        "# with open('quora_questions.pkl', 'wb') as f:\n",
        "#  pickle.dump(dat,f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xrW5C-DRN-08",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Saving the model architecture as a .PNG file"
      ]
    },
    {
      "metadata": {
        "id": "dOXjNYXmuX9-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "plot_model(malstm, to_file='modelLSTM.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OkoNLX74ODqc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plotting the model on Jupyter notebook."
      ]
    },
    {
      "metadata": {
        "id": "e2vODUTovR29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "4f6fa3d4-e3a9-45d9-ad9d-8d7c0cbf896f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "SVG(model_to_dot(malstm).create(prog='dot', format='svg'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"264pt\" viewBox=\"0.00 0.00 346.00 264.00\" width=\"346pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"white\" points=\"-4,4 -4,-260 342,-260 342,4 -4,4\" stroke=\"none\"/>\n<!-- 140285400569616 -->\n<g class=\"node\" id=\"node1\"><title>140285400569616</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 160,-255.5 160,-219.5 0,-219.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80\" y=\"-233.8\">input_1: InputLayer</text>\n</g>\n<!-- 140285400532696 -->\n<g class=\"node\" id=\"node3\"><title>140285400532696</title>\n<polygon fill=\"none\" points=\"67.5,-146.5 67.5,-182.5 270.5,-182.5 270.5,-146.5 67.5,-146.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-160.8\">embedding_1: Embedding</text>\n</g>\n<!-- 140285400569616&#45;&gt;140285400532696 -->\n<g class=\"edge\" id=\"edge1\"><title>140285400569616-&gt;140285400532696</title>\n<path d=\"M101.544,-219.313C113.023,-210.156 127.308,-198.76 139.773,-188.816\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"142.019,-191.501 147.654,-182.529 137.654,-186.029 142.019,-191.501\" stroke=\"black\"/>\n</g>\n<!-- 140285400567880 -->\n<g class=\"node\" id=\"node2\"><title>140285400567880</title>\n<polygon fill=\"none\" points=\"178,-219.5 178,-255.5 338,-255.5 338,-219.5 178,-219.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-233.8\">input_2: InputLayer</text>\n</g>\n<!-- 140285400567880&#45;&gt;140285400532696 -->\n<g class=\"edge\" id=\"edge2\"><title>140285400567880-&gt;140285400532696</title>\n<path d=\"M236.456,-219.313C224.977,-210.156 210.692,-198.76 198.227,-188.816\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"200.346,-186.029 190.346,-182.529 195.981,-191.501 200.346,-186.029\" stroke=\"black\"/>\n</g>\n<!-- 140285400532640 -->\n<g class=\"node\" id=\"node4\"><title>140285400532640</title>\n<polygon fill=\"none\" points=\"110.5,-73.5 110.5,-109.5 227.5,-109.5 227.5,-73.5 110.5,-73.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-87.8\">lstm_1: LSTM</text>\n</g>\n<!-- 140285400532696&#45;&gt;140285400532640 -->\n<g class=\"edge\" id=\"edge3\"><title>140285400532696-&gt;140285400532640</title>\n<path d=\"M169,-146.313C169,-138.289 169,-128.547 169,-119.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"172.5,-119.529 169,-109.529 165.5,-119.529 172.5,-119.529\" stroke=\"black\"/>\n</g>\n<!-- 140285400533368 -->\n<g class=\"node\" id=\"node5\"><title>140285400533368</title>\n<polygon fill=\"none\" points=\"93,-0.5 93,-36.5 245,-36.5 245,-0.5 93,-0.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-14.8\">lambda_1: Lambda</text>\n</g>\n<!-- 140285400532640&#45;&gt;140285400533368 -->\n<g class=\"edge\" id=\"edge5\"><title>140285400532640-&gt;140285400533368</title>\n<path d=\"M169,-73.3129C169,-65.2895 169,-55.5475 169,-46.5691\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"172.5,-46.5288 169,-36.5288 165.5,-46.5289 172.5,-46.5288\" stroke=\"black\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}